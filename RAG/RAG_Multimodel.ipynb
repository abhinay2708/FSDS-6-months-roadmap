{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c9707edf51545f7acf96951d15bf2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5311ef59150748e882766a9c74d92b7d",
              "IPY_MODEL_bbfe1a3a4a7a41bc8b4cb57b0931e759",
              "IPY_MODEL_044624c2748b4382b989ace5717d8cf6"
            ],
            "layout": "IPY_MODEL_3d86a420a6b945b8a91c8f44febfcdeb"
          }
        },
        "5311ef59150748e882766a9c74d92b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e47f57715064d5aa2c52f9a107d23b8",
            "placeholder": "​",
            "style": "IPY_MODEL_92e2bb3eff3a4399be47df853afba250",
            "value": "Fetching 1 files: 100%"
          }
        },
        "bbfe1a3a4a7a41bc8b4cb57b0931e759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f181f11dd4464c749947b341131ef132",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96f8903d38154859bfea3fc027785cb4",
            "value": 1
          }
        },
        "044624c2748b4382b989ace5717d8cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db772064e7c34d369973f8e0720fb2c9",
            "placeholder": "​",
            "style": "IPY_MODEL_fdd725c11d1d492e849a1c6163b5d044",
            "value": " 1/1 [00:00&lt;00:00, 67.24it/s]"
          }
        },
        "3d86a420a6b945b8a91c8f44febfcdeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e47f57715064d5aa2c52f9a107d23b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e2bb3eff3a4399be47df853afba250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f181f11dd4464c749947b341131ef132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f8903d38154859bfea3fc027785cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db772064e7c34d369973f8e0720fb2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd725c11d1d492e849a1c6163b5d044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TVxfxfenbILv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install chromadb\n",
        "!pip install datasets\n",
        "!pip install pyarrow\n",
        "!pip install open-clip-torch\n",
        "!pip install sentence-transformers\n",
        "!pip install langchain_core langchain_openai\n",
        "!pip install torchcodec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from IPython.display import HTML, display, Image, Markdown, Video, Audio\n",
        "from typing import Optional, Sequence, List, Dict, Union\n",
        "\n",
        "import soundfile as sf\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import ClapModel, ClapProcessor\n",
        "from datasets import load_dataset\n",
        "\n",
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
        "from chromadb.utils.data_loaders import ImageLoader\n",
        "from chromadb.api.types import Document, Embedding, EmbeddingFunction, URI, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "import base64\n",
        "import torch\n",
        "import json\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "FTJprLyqbdGd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"mm_vdb\"\n",
        "client = chromadb.PersistentClient(path=path)"
      ],
      "metadata": {
        "id": "__lSouRibtgf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"ashraq/esc50\") #LOAD THE DATASET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbM4bEccb94Q",
        "outputId": "44e3c5bb-c76c-400a-f480-ca5fbabf6b52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory to save audio files\n",
        "path = \"esc50\"\n",
        "os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Process and save audio files\n",
        "for item in ds['train']:\n",
        "    audio_array = item['audio']['array']\n",
        "    sample_rate = item['audio']['sampling_rate']\n",
        "    file_name = item['filename']\n",
        "    target_path = os.path.join(path, file_name)\n",
        "\n",
        "    # Write the audio file to the new directory\n",
        "    sf.write(target_path, audio_array, sample_rate)\n",
        "\n",
        "print(\"All audio files have been processed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoCu-KxMcATB",
        "outputId": "5e02691b-f488-4ea5-e63a-f8dbb8d383fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All audio files have been processed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f88264a"
      },
      "source": [
        "class AudioLoader(DataLoader[List[Optional[Dict[str, any]]]]):\n",
        "    def __init__(self, target_sample_rate: int = 48000) -> None:\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "\n",
        "    def _load_audio(self, uri: Optional[URI]) -> Optional[Dict[str, any]]:\n",
        "        if uri is None:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            waveform, sample_rate = torchaudio.load(uri)\n",
        "\n",
        "            # Resample if necessary\n",
        "            if sample_rate != self.target_sample_rate:\n",
        "                resampler = torchaudio.transforms.Resample(sample_rate, self.target_sample_rate)\n",
        "                waveform = resampler(waveform)\n",
        "\n",
        "            # Convert to mono if stereo\n",
        "            if waveform.shape[0] > 1:\n",
        "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "            return {\"waveform\": waveform.squeeze(), \"uri\": uri}\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading audio file {uri}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def __call__(self, uris: Sequence[Optional[URI]]) -> List[Optional[Dict[str, any]]]:\n",
        "        return [self._load_audio(uri) for uri in uris]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CLAPEmbeddingFunction(EmbeddingFunction[Union[Document, Dict[str, any]]]):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = \"laion/larger_clap_general\",\n",
        "        device: str = None\n",
        "    ) -> None:\n",
        "        if device is None:\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model = ClapModel.from_pretrained(model_name).to(device)\n",
        "        self.processor = ClapProcessor.from_pretrained(model_name)\n",
        "        self.device = device\n",
        "\n",
        "    def _encode_audio(self, audio: torch.Tensor) -> Embedding:\n",
        "        inputs = self.processor(audios=audio.numpy(), sampling_rate=48000, return_tensors=\"pt\")\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            audio_embedding = self.model.get_audio_features(**inputs)\n",
        "        return audio_embedding.squeeze().cpu().numpy().tolist()\n",
        "\n",
        "    def _encode_text(self, text: Document) -> Embedding:\n",
        "        inputs = self.processor(text=text, return_tensors=\"pt\")\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            text_embedding = self.model.get_text_features(**inputs)\n",
        "        return text_embedding.squeeze().cpu().numpy().tolist()\n",
        "\n",
        "    def __call__(self, input: Union[List[Document], List[Optional[Dict[str, any]]]]) -> List[Optional[Embedding]]:\n",
        "        embeddings = []\n",
        "        for item in input:\n",
        "            if isinstance(item, dict) and 'waveform' in item:\n",
        "                embeddings.append(self._encode_audio(item['waveform']))\n",
        "            elif isinstance(item, str):\n",
        "                embeddings.append(self._encode_text(item))\n",
        "            elif item is None:\n",
        "                embeddings.append(None)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported input type: {type(item)}\")\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "QhK7ORNAcN0x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_collection = client.get_or_create_collection(\n",
        "    name='audio_collection',\n",
        "    embedding_function=CLAPEmbeddingFunction(),\n",
        "    data_loader=AudioLoader()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9c9707edf51545f7acf96951d15bf2ad",
            "5311ef59150748e882766a9c74d92b7d",
            "bbfe1a3a4a7a41bc8b4cb57b0931e759",
            "044624c2748b4382b989ace5717d8cf6",
            "3d86a420a6b945b8a91c8f44febfcdeb",
            "1e47f57715064d5aa2c52f9a107d23b8",
            "92e2bb3eff3a4399be47df853afba250",
            "f181f11dd4464c749947b341131ef132",
            "96f8903d38154859bfea3fc027785cb4",
            "db772064e7c34d369973f8e0720fb2c9",
            "fdd725c11d1d492e849a1c6163b5d044"
          ]
        },
        "id": "6go0eY-idZkw",
        "outputId": "b74b7626-3baf-499a-fce2-4e5805ea7ec7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c9707edf51545f7acf96951d15bf2ad"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes a couple mins with GPU\n",
        "def add_audio(audio_collection, folder_path):\n",
        "    # List to store IDs and URIs\n",
        "    ids = []\n",
        "    uris = []\n",
        "\n",
        "    # Iterate through all files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.wav'):\n",
        "            file_id = os.path.splitext(filename)[0]\n",
        "            file_uri = os.path.join(folder_path, filename)\n",
        "\n",
        "            ids.append(file_id)\n",
        "            uris.append(file_uri)\n",
        "\n",
        "    # Add files to the collection\n",
        "    audio_collection.add(ids=ids, uris=uris)\n",
        "\n",
        "# Running it\n",
        "folder_path = 'esc50'\n",
        "add_audio(audio_collection, folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wB7e-ZMdcTd",
        "outputId": "ad5179c7-a96a-42f6-eba7-11bf65e587d1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NUBSqi1Mdtok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}