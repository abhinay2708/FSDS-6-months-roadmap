{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ed9f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.84  Python-3.10.0 torch-2.2.2+cpu CPU (AMD Ryzen 5 7430U with Radeon Graphics)\n",
      "Setup complete  (12 CPUs, 15.4 GB RAM, 161.6/475.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd0102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.84 ðŸš€ Python-3.10.0 torch-2.2.2+cpu CPU (AMD Ryzen 5 7430U with Radeon Graphics)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
      "image 1/1 c:\\Users\\abhin\\FSDS\\Deep_Learning\\yolo\\zidane.jpg: 384x640 2 persons, 1 tie, 161.5ms\n",
      "Speed: 3.7ms preprocess, 161.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict11\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/49.2k [00:00<?, ?B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.2k/49.2k [00:00<00:00, 2.66MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image with YOLO11n\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022e071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.84 ðŸš€ Python-3.10.0 torch-2.2.2+cpu CPU (AMD Ryzen 5 7430U with Radeon Graphics)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Downloading https://images.picxy.com/cache/2019/7/25/7cb6f63a656f23f38c4fff9a4cf219bc.jpg to '7cb6f63a656f23f38c4fff9a4cf219bc.jpg'...\n",
      "image 1/1 c:\\Users\\abhin\\FSDS\\Deep_Learning\\yolo\\7cb6f63a656f23f38c4fff9a4cf219bc.jpg: 448x640 1 person, 1 cup, 1 chair, 1 laptop, 143.3ms\n",
      "Speed: 2.5ms preprocess, 143.3ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict12\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/420k [00:00<?, ?B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 420k/420k [00:00<00:00, 8.52MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image with YOLO11n\n",
    "!yolo predict model=yolov8n.pt source='https://images.picxy.com/cache/2019/7/25/7cb6f63a656f23f38c4fff9a4cf219bc.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13253af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
